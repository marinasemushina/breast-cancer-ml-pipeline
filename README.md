# breast-cancer-ml-pipeline

# Автоматизация и оркестрация пайплайна машинного обучения с использованием Apache Airflow и облачного хранилища

# Описание проекта

Цель проекта — разработать автоматизированный ETL-процесс для построения предиктивной модели диагностики рака молочной железы на основе датасета Breast Cancer Wisconsin Diagnostic.

Пайплайн реализован с помощью Apache Airflow и Python. Результаты модели и метрики сохраняются в облачное хранилище.

## 1. Формулировка задачи машинного обучения
Задача — бинарная классификация. Необходимо на основе измерений морфологических характеристик клеток предсказать диагноз: доброкачественная (B — benign) или злокачественная (M — malignant) опухоль.

Входные данные: 30 числовых признаков, полученных из изображений клеток.

Целевая переменная: diagnosis — метка класса (B или M).

Цель: построить модель, максимально точно предсказывающую диагноз на новых данных.

## 2. Структура пайплайна

Пайплайн состоит из следующих этапов:

Описание

1. Загрузка данных	Загрузка CSV-файла с исходным датасетом из внешнего источника.
2. Предобработка	Очистка данных (удаление лишних столбцов, обработка пропусков), кодирование целевой переменной, масштабирование признаков.
3. Обучение модели	Обучение классификатора (например, RandomForest или LogisticRegression) на подготовленных данных.
4. Оценка модели	Расчёт метрик качества (accuracy, precision, recall, F1-score, ROC-AUC).
5. Сохранение результатов	Сохранение обученной модели и метрик в облачное хранилище (например, AWS S3, Google Cloud Storage).
   
## 3. Диаграмма пайплайна

load_data() -> preprocess() -> train_model() -> evaluate() -> save_results() -> upload()
   

## 5. Краткое описание шагов

Загрузка данных: скачиваем датасет Breast Cancer Wisconsin Diagnostic в формате CSV.

Предобработка: удаляем столбец Unnamed: 32 (пустой), кодируем целевую переменную diagnosis в числовой формат (M=1, B=0), масштабируем признаки с помощью StandardScaler.

Обучение: делим данные на train/test, обучаем модель классификации (например, RandomForestClassifier) с настройкой гиперпараметров.

Оценка: вычисляем основные метрики качества, строим ROC-кривую.

Сохранение: сериализуем модель (pickle/joblib), сохраняем метрики и модель в облачное хранилище, обеспечиваем доступность для дальнейшего использования.

## 6. Дополнительно

Весь пайплайн автоматизирован через Apache Airflow, где каждый этап реализован как отдельный таск DAG.

Логи работы сохраняются в папке logs/.

Финальные артефакты и метрики — в results/.

Код модулей разбит по папкам etl/ для удобства поддержки и масштабирования.
