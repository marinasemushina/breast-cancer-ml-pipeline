# breast-cancer-ml-pipeline

# Автоматизация и оркестрация пайплайна машинного обучения с использованием Apache Airflow и облачного хранилища

# Описание проекта

Цель проекта — разработать автоматизированный ETL-процесс для построения предиктивной модели диагностики рака молочной железы на основе датасета Breast Cancer Wisconsin Diagnostic.

Пайплайн реализован с помощью Apache Airflow и Python. Результаты модели и метрики сохраняются в облачное хранилище.

## 1. Формулировка задачи машинного обучения
Задача — бинарная классификация. Необходимо на основе измерений морфологических характеристик клеток предсказать диагноз: доброкачественная (B — benign) или злокачественная (M — malignant) опухоль.

Входные данные: 30 числовых признаков, полученных из изображений клеток.

Целевая переменная: diagnosis — метка класса (B или M).

Цель: построить модель, максимально точно предсказывающую диагноз на новых данных.

## 2. Структура пайплайна

.

├── dags/                         # Airflow DAG

├── etl/                          # Modular ETL scripts

├── results/                      # Saved model and metrics

├── logs/                         # Airflow logs

├── config.py                     # Paths configuration

└── README.md

Пайплайн состоит из следующих этапов:

Описание

1. Загрузка данных:	Загрузка CSV-файла с исходным датасетом из внешнего источника.
2. Предобработка:	Очистка данных (удаление лишних столбцов, обработка пропусков), кодирование целевой переменной, масштабирование признаков.
3. Обучение модели:	Обучение классификатора на подготовленных данных.
4. Оценка модели:	Расчёт метрик качества (accuracy, precision, recall, F1-score).
5. Сохранение результатов:	Сохранение обученной модели и метрик в облачное хранилище.
   
## 3. Диаграмма пайплайна

load_data() -> preprocess() -> train_model() -> evaluate() -> save_results() -> upload()
   

## 5. Краткое описание шагов

Загрузка данных: скачиваем датасет Breast Cancer Wisconsin Diagnostic в формате CSV.

Предобработка: удаляем столбец Unnamed: 32 (пустой), кодируем целевую переменную diagnosis в числовой формат (M=1, B=0), масштабируем признаки с помощью StandardScaler.

Обучение: делим данные на train/test, обучаем модель классификации с настройкой гиперпараметров.

Оценка: вычисляем основные метрики качества.

Сохранение: сериализуем модель (pickle/joblib), сохраняем метрики и модель в облачное хранилище, обеспечиваем доступность для дальнейшего использования.

## 6. Дополнительно

Весь пайплайн автоматизирован через Apache Airflow, где каждый этап реализован как отдельный таск DAG.

Логи работы сохраняются в папке logs/.

Финальные артефакты и метрики — в results/.

Код модулей разбит по папкам etl/ для удобства поддержки и масштабирования.

## 7. Анализ ошибок и устойчивости

### Потенциальные точки сбоя

1. Проблемы с источником данных

Где может «упасть» процесс?

При попытке подключения к API или БД для извлечения данных.
Во время обработки данных, если источник временно недоступен.

Какие исключения могут возникнуть?

ConnectionError: Проблемы с сетью или недоступность сервера.
TimeoutError: Превышение времени ожидания ответа от источника данных.

2. Проблемы с данными

Что произойдет при потере соединения с источником данных?

Пайплайн может остановиться, если не реализованы механизмы повторных попыток.

Что будет, если источник отдает невалидные данные?

Программа может выбросить исключение при попытке обработки данных (например, ValueError или TypeError).
Необходимо предусмотреть валидацию данных перед их использованием.

3. Проблемы с моделью

Что произойдет, если модель не обучается или выдает ошибку?

Если модель не может быть обучена, это может привести к исключениям, таким как FitError или ValueError.
Программа должна корректно обрабатывать эти исключения и продолжать выполнение других задач.

### Устойчивость пайплайна

Чтобы обеспечить устойчивость нашего пайплайна, мы внедрили следующие механизмы:

1. Логирование на каждом шаге

Вся информация о выполнении задач, включая ошибки и предупреждения, записывается в логи. Это позволяет отслеживать процесс и быстро реагировать на сбои.

2. Использование Airflow

Retries: Каждая задача настроена на повторные попытки выполнения в случае неудачи. Например, если задача по извлечению данных не удалась, Airflow автоматически попытается выполнить её снова.
Timeout: Установлены тайм-ауты для задач, чтобы избежать бесконечного ожидания.
Failure Callbacks: В случае сбоя задачи вызывается специальный коллбек, который может отправить уведомление или выполнить дополнительные действия для обработки ошибки.

3. Изолированные модули

Каждая задача в пайплайне реализована как отдельный модуль, что позволяет изолировать сбои. Например, если задача по обработке данных завершилась неудачей, это не повлияет на задачи, связанные с загрузкой данных или обучением модели.

4. Проверка и валидация данных

Реализованы проверки схемы и валидация данных перед их использованием. Это позволяет избежать ошибок, связанных с невалидными или неполными данными.

5. Обработка исключений

Все ключевые операции обернуты в блоки try-except, что позволяет ловить и обрабатывать исключения, не останавливая весь пайплайн.


